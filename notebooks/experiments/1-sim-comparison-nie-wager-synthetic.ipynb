{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of CCT- & CMC-learners and other approaches (simulations)\n",
    "\n",
    "**On Nie and Wager (2021) synthetic data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from crepes_weighted import WrapRegressor\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "sys.path.append('../..')\n",
    "from src.cmc_metalearners.cmc_metalearners import CMC_S_Learner, CMC_T_Learner, CMC_X_Learner, CCT_Learner\n",
    "from src.wcp.wcp import NaiveWCP, NestedWCP\n",
    "from src.conformal_metalearners.CM_learner import CM_learner\n",
    "from src.datasets.nie_wager_synthetic import (simulate_nuisance_and_easy_treatment,\n",
    "                                             simulate_randomized_trial,\n",
    "                                             simulate_easy_propensity_difficult_baseline,\n",
    "                                             simulate_unrelated_treatment_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_save_data = True\n",
    "heteroscedastic_epsilon = False\n",
    "NSim = 100\n",
    "alphas = [0.1]\n",
    "learner = RandomForestRegressor\n",
    "learner_name = \"RF\"\n",
    "MC_samples = 100\n",
    "normalized_conformal = True\n",
    "if normalized_conformal:\n",
    "    normalized_conformal_name = \"normalized\"\n",
    "else:\n",
    "    normalized_conformal_name = \"nonnormalized\"\n",
    "max_min_y = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be10404676fe470cb4e7cddf70b4e5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c675f30347047329ea3921f838b970b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, setup in enumerate([simulate_nuisance_and_easy_treatment, simulate_randomized_trial, simulate_easy_propensity_difficult_baseline, simulate_unrelated_treatment_control]):\n",
    "    if i == 0:\n",
    "        setup_name = \"A\"\n",
    "    elif i == 1:\n",
    "        setup_name = \"B\"\n",
    "    elif i == 2:\n",
    "        setup_name = \"C\"\n",
    "    else:\n",
    "        setup_name = \"D\"\n",
    "    for n in tqdm(range(NSim)):\n",
    "        if heteroscedastic_epsilon:\n",
    "            path_train = f\"../../data/simulations/nie_wager/setup{setup_name}/simulations_{setup_name}_{n}_train_heteroscedastic.csv\"\n",
    "            path_test = f\"../../data/simulations/nie_wager/setup{setup_name}/simulations_{setup_name}_{n}_test_heteroscedastic.csv\"\n",
    "        else:\n",
    "            path_train = f\"../../data/simulations/nie_wager/setup{setup_name}/simulations_{setup_name}_{n}_train.csv\"\n",
    "            path_test = f\"../../data/simulations/nie_wager/setup{setup_name}/simulations_{setup_name}_{n}_test.csv\"\n",
    "        if get_save_data:\n",
    "            ds_train = pd.read_csv(path_train)\n",
    "            ds_test = pd.read_csv(path_test)\n",
    "            y_train = ds_train[\"y\"].values\n",
    "            y_test = ds_test[\"y\"].values\n",
    "            X_train = ds_train[[f\"X{i}\" for i in range(5)]].values\n",
    "            X_test = ds_test[[f\"X{i}\" for i in range(5)]].values\n",
    "            W_train = ds_train[\"W\"].values\n",
    "            W_test = ds_test[\"W\"].values\n",
    "            tau_train = ds_train[\"tau\"].values\n",
    "            tau_test = ds_test[\"tau\"].values\n",
    "            b_train = ds_train[\"b\"].values\n",
    "            b_test = ds_test[\"b\"].values\n",
    "            ps_train = ds_train[\"ps\"].values\n",
    "            ps_test = ds_test[\"ps\"].values\n",
    "            y0_train = ds_train[\"y0\"].values\n",
    "            y0_test = ds_test[\"y0\"].values\n",
    "            y1_train = ds_train[\"y1\"].values\n",
    "            y1_test = ds_test[\"y1\"].values\n",
    "            ite_train = ds_train[\"ite\"].values\n",
    "            ite_test = ds_test[\"ite\"].values\n",
    "        else:\n",
    "            y, X, treatment, tau, b, e, y0, y1 = setup(n=5000, c=0.0, heteroscedastic=heteroscedastic_epsilon)\n",
    "            ite = y1 - y0\n",
    "            ps = e\n",
    "            (y_train, y_test, X_train, X_test,\n",
    "            W_train, W_test,\n",
    "            tau_train, tau_test, b_train, b_test,\n",
    "            ps_train, ps_test, y0_train, y0_test,\n",
    "            y1_train, y1_test, ite_train, ite_test) = train_test_split(y, X, treatment, tau, b, ps, y0, y1, ite,\n",
    "                                                                        test_size=0.5)\n",
    "            df_X_train = pd.DataFrame(X_train, columns=[f\"X{i}\" for i in range(X_train.shape[1])])\n",
    "            df_X_test = pd.DataFrame(X_test, columns=[f\"X{i}\" for i in range(X_test.shape[1])])\n",
    "            ds_train = pd.concat((df_X_train, pd.DataFrame({\n",
    "                \"y\": y_train,\n",
    "                \"W\": W_train,\n",
    "                \"tau\": tau_train,\n",
    "                \"b\": b_train,\n",
    "                \"ps\": ps_train,\n",
    "                \"y0\": y0_train,\n",
    "                \"y1\": y1_train,\n",
    "                \"ite\": ite_train\n",
    "            })), axis=1)\n",
    "            ds_test = pd.concat((df_X_test, pd.DataFrame({\n",
    "                \"y\": y_test,\n",
    "                \"W\": W_test,\n",
    "                \"tau\": tau_test,\n",
    "                \"b\": b_test,\n",
    "                \"ps\": ps_test,\n",
    "                \"y0\": y0_test,\n",
    "                \"y1\": y1_test,\n",
    "                \"ite\": ite_test\n",
    "            })), axis=1)\n",
    "            ds_train.to_csv(path_train, index=False)\n",
    "            ds_test.to_csv(path_test, index=False)\n",
    "        # Initialize the learner\n",
    "        conformal_pseudo_MC_T_Learner = CMC_T_Learner(\n",
    "            learner(),\n",
    "            learner(),\n",
    "            normalized_conformal=normalized_conformal,\n",
    "            pseudo_MC=True,\n",
    "            MC_samples=MC_samples,\n",
    "            max_min_y=max_min_y\n",
    "        )\n",
    "        conformal_pseudo_MC_T_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "        conformal_MC_T_Learner = CMC_T_Learner(\n",
    "            learner(),\n",
    "            learner(),\n",
    "            normalized_conformal=normalized_conformal,\n",
    "            pseudo_MC=False,\n",
    "            MC_samples=MC_samples,\n",
    "            max_min_y=max_min_y\n",
    "        )\n",
    "        conformal_MC_T_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "        conformal_pseudo_MC_S_Learner = CMC_S_Learner(\n",
    "            learner(),\n",
    "            normalized_conformal=normalized_conformal,\n",
    "            pseudo_MC=True,\n",
    "            MC_samples=MC_samples,\n",
    "            max_min_y=max_min_y\n",
    "        )\n",
    "        with warnings.catch_warnings():\n",
    "            conformal_pseudo_MC_S_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "        conformal_MC_S_Learner = CMC_S_Learner(\n",
    "            learner(),\n",
    "            normalized_conformal=normalized_conformal,\n",
    "            pseudo_MC=False,\n",
    "            MC_samples=MC_samples,\n",
    "            max_min_y=max_min_y\n",
    "        )\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            conformal_MC_S_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "\n",
    "        conformal_pseudo_MC_X_Learner = CMC_X_Learner(\n",
    "            learner(),\n",
    "            learner(),\n",
    "            learner(),\n",
    "            normalized_conformal=normalized_conformal,\n",
    "            pseudo_MC=True,\n",
    "            MC_samples=MC_samples,\n",
    "            max_min_y=max_min_y\n",
    "        )\n",
    "        # Fit the learner\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            conformal_pseudo_MC_X_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "        conformal_MC_X_Learner = CMC_X_Learner(\n",
    "            learner(),\n",
    "            learner(),\n",
    "            learner(),\n",
    "            normalized_conformal=normalized_conformal,\n",
    "            pseudo_MC=False,\n",
    "            MC_samples=MC_samples,\n",
    "            max_min_y=max_min_y\n",
    "        )\n",
    "\n",
    "        # Fit the learner\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            conformal_MC_X_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "        conformal_CT_learner = CCT_Learner(learner(), learner(), normalized_conformal=normalized_conformal)\n",
    "        conformal_CT_learner.fit(X_train, y_train, W_train, p=ps_train)\n",
    "\n",
    "        naive_WCP = NaiveWCP(\n",
    "                        learner(),\n",
    "                        learner(),\n",
    "                        normalized_conformal=normalized_conformal)\n",
    "\n",
    "\n",
    "        naive_WCP.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "        (X_train_nuisance, X_train_cal,\n",
    "            y_train_nuisance, y_train_cal,\n",
    "            y0_train_nuisance, y0_train_cal,\n",
    "            y1_train_nuisance, y1_train_cal,\n",
    "            W_train_nuisance, W_train_cal,\n",
    "            ite_train_nuisance, ite_train_cal) = train_test_split(\n",
    "                X_train, y_train, y0_train, y1_train, W_train, ite_train, test_size=0.5, random_state=n\n",
    "        )\n",
    "\n",
    "        conformal_y0 = WrapRegressor(learner())\n",
    "        conformal_y0.fit(X_train_nuisance, y0_train_nuisance)\n",
    "        conformal_y0.calibrate(X_train_cal, y0_train_cal, cps=True)\n",
    "        conformal_y1 = WrapRegressor(learner())\n",
    "        conformal_y1.fit(X_train_nuisance, y1_train_nuisance)\n",
    "        conformal_y1.calibrate(X_train_cal, y1_train_cal, cps=True)\n",
    "        conformal_ite = WrapRegressor(learner())\n",
    "        conformal_ite.fit(X_train_nuisance, ite_train_nuisance)\n",
    "        conformal_ite.calibrate(X_train_cal, ite_train_cal, cps=True)\n",
    "        conformal_y_cond0 = WrapRegressor(learner())\n",
    "        conformal_y_cond0.fit(X_train_nuisance[W_train_nuisance == 0], y_train_nuisance[W_train_nuisance == 0])\n",
    "        conformal_y_cond0.calibrate(X_train_cal[W_train_cal == 0], y_train_cal[W_train_cal == 0], cps=True)\n",
    "        conformal_y_cond1 = WrapRegressor(learner())\n",
    "        conformal_y_cond1.fit(X_train_nuisance[W_train_nuisance == 1], y_train_nuisance[W_train_nuisance == 1])\n",
    "        conformal_y_cond1.calibrate(X_train_cal[W_train_cal == 1], y_train_cal[W_train_cal == 1], cps=True)\n",
    "\n",
    "        int_results_y0 = []\n",
    "        int_results_y1 = []\n",
    "        int_results_pseudo_MC_T_ite = []\n",
    "        int_results_MC_T_ite = []\n",
    "        int_results_pseudo_MC_S_ite = []\n",
    "        int_results_MC_S_ite = []\n",
    "        int_results_pseudo_MC_X_ite = []\n",
    "        int_results_MC_X_ite = []\n",
    "        int_results_CT_ite = []\n",
    "        int_results_CM_ite = []\n",
    "        int_results_naive_ite = []\n",
    "        int_results_exact_ite = []\n",
    "        int_results_inexact_ite = []\n",
    "        int_results_y0_oracle = []\n",
    "        int_results_y1_oracle = []\n",
    "        int_results_ite_oracle = []\n",
    "        int_results_y_cond0 = []\n",
    "        int_results_y_cond1 = []\n",
    "\n",
    "        coverage_y0 = []\n",
    "        coverage_y1 = []\n",
    "        coverage_pseudo_MC_T_ite = []\n",
    "        coverage_MC_T_ite = []\n",
    "        coverage_pseudo_MC_S_ite = []\n",
    "        coverage_MC_S_ite = []\n",
    "        coverage_pseudo_MC_X_ite = []\n",
    "        coverage_MC_X_ite = []\n",
    "        coverage_CT_ite = []\n",
    "        coverage_CM_ite = []\n",
    "        coverage_naive_ite = []\n",
    "        coverage_exact_ite = []\n",
    "        coverage_inexact_ite = []\n",
    "        coverage_y0_oracle = []\n",
    "        coverage_y1_oracle = []\n",
    "        coverage_ite_oracle = []\n",
    "        coverage_y_cond0 = []\n",
    "        coverage_y_cond1 = []\n",
    "\n",
    "        int_width_y0 = []\n",
    "        int_width_y1 = []\n",
    "        int_width_pseudo_MC_T = []\n",
    "        int_width_MC_T = []\n",
    "        int_width_pseudo_MC_S = []\n",
    "        int_width_MC_S = []\n",
    "        int_width_pseudo_MC_X = []\n",
    "        int_width_MC_X = []\n",
    "        int_width_CT = []\n",
    "        int_width_CM = []\n",
    "        int_width_naive_ite = []\n",
    "        int_width_exact_ite = []\n",
    "        int_width_inexact_ite = []\n",
    "        int_width_y0_oracle = []\n",
    "        int_width_y1_oracle = []\n",
    "        int_width_ite_oracle = []\n",
    "        int_width_y_cond0 = []\n",
    "        int_width_y_cond1 = []\n",
    "\n",
    "\n",
    "        rmse_y0 = []\n",
    "        rmse_y1 = []\n",
    "        rmse_pseudo_MC_T_ite, rmse_pseudo_MC_T_ite_conformal_mean = [], []\n",
    "        rmse_MC_T_ite,  rmse_MC_T_ite_conformal_mean = [], []\n",
    "        rmse_pseudo_MC_S_ite, rmse_pseudo_MC_S_ite_conformal_mean = [], []\n",
    "        rmse_MC_S_ite, rmse_MC_S_ite_conformal_mean = [], []\n",
    "        rmse_pseudo_MC_X_ite, rmse_pseudo_MC_X_ite_conformal_mean = [], []\n",
    "        rmse_MC_X_ite, rmse_MC_X_ite_conformal_mean = [], []\n",
    "        rmse_CT_ite = []\n",
    "        rmse_CM_ite = []\n",
    "        rmse_naive_ite = []\n",
    "        rmse_exact_ite = []\n",
    "        rmse_inexact_ite = []\n",
    "        rmse_y0_oracle = []\n",
    "        rmse_y1_oracle = []\n",
    "        rmse_ite_oracle = []\n",
    "        rmse_y_cond0 = []\n",
    "        rmse_y_cond1 = []\n",
    "\n",
    "\n",
    "        for alpha in alphas:\n",
    "            int_pseudo_MC_ite_test = conformal_pseudo_MC_T_Learner.predict_int(X_test, confidence=1-alpha)\n",
    "            int_MC_ite_test = conformal_MC_T_Learner.predict_int(X_test, confidence=1-alpha)\n",
    "            int_pseudo_MC_S_ite_test = conformal_pseudo_MC_S_Learner.predict_int(X_test, confidence=1-alpha)\n",
    "            int_MC_S_ite_test = conformal_MC_S_Learner.predict_int(X_test, confidence=1-alpha)\n",
    "            int_pseudo_MC_X_ite_test = conformal_pseudo_MC_X_Learner.predict_int(X_test, confidence=1-alpha)\n",
    "            int_MC_X_ite_test = conformal_MC_X_Learner.predict_int(X_test, confidence=1-alpha)\n",
    "            int_CT_ite_test = conformal_CT_learner.predict_int(X_test, confidence=1-alpha, p=ps_test)\n",
    "            int_y0_test = conformal_CT_learner.predict_int_y0(X_test, confidence=1-alpha, p=ps_test)\n",
    "            int_y1_test = conformal_CT_learner.predict_int_y1(X_test, confidence=1-alpha, p=ps_test)\n",
    "            conformal_Learner = CM_learner(metalearner=\"DR\", alpha=alpha)\n",
    "            conformal_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "            int_CM_ite_test = conformal_Learner.predict_int(X_test)\n",
    "            int_naive_ite_test = naive_WCP.predict_int(X_test, ps_test, confidence=1-alpha)\n",
    "            exact_wcp = NestedWCP(\n",
    "                            learner(),\n",
    "                            learner(),\n",
    "                            learner(),\n",
    "                            normalized_conformal=normalized_conformal,\n",
    "                            exact=True)\n",
    "            exact_wcp.fit(X_train, y_train, W_train, ps_train, confidence=1-alpha)\n",
    "            int_exact_ite_test = exact_wcp.predict_int(X_test, ps_test)\n",
    "            inexact_wcp = NestedWCP(\n",
    "                            learner(),\n",
    "                            learner(),\n",
    "                            normalized_conformal=normalized_conformal,\n",
    "                            exact=False)\n",
    "            inexact_wcp.fit(X_train, y_train, W_train, ps_train, confidence=1-alpha)\n",
    "            int_inexact_ite_test = inexact_wcp.predict_int(X_test, ps_test)\n",
    "            int_y0_oracle = conformal_y0.predict_int(X_test, confidence=1-alpha)\n",
    "            int_y1_oracle = conformal_y1.predict_int(X_test, confidence=1-alpha)\n",
    "            int_ite_oracle = conformal_ite.predict_int(X_test, confidence=1-alpha)\n",
    "            int_y_cond0 = conformal_y_cond0.predict_int(X_test[W_test == 0], confidence=1-alpha)\n",
    "            int_y_cond1 = conformal_y_cond1.predict_int(X_test[W_test == 1], confidence=1-alpha)\n",
    "\n",
    "            int_results_y0.append(int_y0_test)\n",
    "            int_results_y1.append(int_y1_test)\n",
    "            int_results_pseudo_MC_T_ite.append(int_pseudo_MC_ite_test)\n",
    "            int_results_MC_T_ite.append(int_MC_ite_test)\n",
    "            int_results_pseudo_MC_S_ite.append(int_pseudo_MC_S_ite_test)\n",
    "            int_results_MC_S_ite.append(int_MC_S_ite_test)\n",
    "            int_results_pseudo_MC_X_ite.append(int_pseudo_MC_X_ite_test)\n",
    "            int_results_MC_X_ite.append(int_MC_X_ite_test)\n",
    "            int_results_CT_ite.append(int_CT_ite_test)\n",
    "            int_results_CM_ite.append(int_CM_ite_test)\n",
    "            int_results_naive_ite.append(int_naive_ite_test)\n",
    "            int_results_exact_ite.append(int_exact_ite_test)\n",
    "            int_results_inexact_ite.append(int_inexact_ite_test)\n",
    "            int_results_y0_oracle.append(int_y0_oracle)\n",
    "            int_results_y1_oracle.append(int_y1_oracle)\n",
    "            int_results_ite_oracle.append(int_ite_oracle)\n",
    "            int_results_y_cond0.append(int_y_cond0)\n",
    "            int_results_y_cond1.append(int_y_cond1)\n",
    "\n",
    "            coverage_y0.append(np.mean((int_y0_test[:, 0] < y0_test) &  (int_y0_test[:, 1] > y0_test)))\n",
    "            coverage_y1.append(np.mean((int_y1_test[:, 0] < y1_test) &  (int_y1_test[:, 1] > y1_test)))\n",
    "            coverage_pseudo_MC_T_ite.append(np.mean((int_pseudo_MC_ite_test[:, 0] < ite_test) &  (int_pseudo_MC_ite_test[:, 1] > ite_test)))\n",
    "            coverage_MC_T_ite.append(np.mean((int_MC_ite_test[:, 0] < ite_test) &  (int_MC_ite_test[:, 1] > ite_test)))\n",
    "            coverage_pseudo_MC_S_ite.append(np.mean((int_pseudo_MC_S_ite_test[:, 0] < ite_test) &  (int_pseudo_MC_S_ite_test[:, 1] > ite_test)))\n",
    "            coverage_MC_S_ite.append(np.mean((int_MC_S_ite_test[:, 0] < ite_test) &  (int_MC_S_ite_test[:, 1] > ite_test)))\n",
    "            coverage_pseudo_MC_X_ite.append(np.mean((int_pseudo_MC_X_ite_test[:, 0] < ite_test) &  (int_pseudo_MC_X_ite_test[:, 1] > ite_test)))\n",
    "            coverage_MC_X_ite.append(np.mean((int_MC_X_ite_test[:, 0] < ite_test) &  (int_MC_X_ite_test[:, 1] > ite_test)))\n",
    "            coverage_CT_ite.append(np.mean((int_CT_ite_test[:, 0] < ite_test) &  (int_CT_ite_test[:, 1] > ite_test)))\n",
    "            coverage_CM_ite.append(np.mean((int_CM_ite_test[:, 0] < ite_test) &  (int_CM_ite_test[:, 1] > ite_test)))\n",
    "            coverage_naive_ite.append(np.mean((int_naive_ite_test[:, 0] < ite_test) &  (int_naive_ite_test[:, 1] > ite_test)))\n",
    "            coverage_exact_ite.append(np.mean((int_exact_ite_test[:, 0] < ite_test) &  (int_exact_ite_test[:, 1] > ite_test)))\n",
    "            coverage_inexact_ite.append(np.mean((int_inexact_ite_test[:, 0] < ite_test) &  (int_inexact_ite_test[:, 1] > ite_test)))\n",
    "            coverage_y0_oracle.append(np.mean((int_y0_oracle[:, 0] < y0_test) &  (int_y0_oracle[:, 1] > y0_test)))\n",
    "            coverage_y1_oracle.append(np.mean((int_y1_oracle[:, 0] < y1_test) &  (int_y1_oracle[:, 1] > y1_test)))\n",
    "            coverage_ite_oracle.append(np.mean((int_ite_oracle[:, 0] < ite_test) &  (int_ite_oracle[:, 1] > ite_test)))\n",
    "            coverage_y_cond0.append(np.mean((int_y_cond0[:, 0] < y_test[W_test == 0]) &  (int_y_cond0[:, 1] > y_test[W_test == 0])))\n",
    "            coverage_y_cond1.append(np.mean((int_y_cond1[:, 0] < y_test[W_test == 1]) &  (int_y_cond1[:, 1] > y_test[W_test == 1])))\n",
    "\n",
    "            int_width_y0.append(np.diff(int_y0_test).mean())\n",
    "            int_width_y1.append(np.diff(int_y1_test).mean())\n",
    "            int_width_pseudo_MC_T.append(np.diff(int_pseudo_MC_ite_test).mean())\n",
    "            int_width_MC_T.append(np.diff(int_MC_ite_test).mean())\n",
    "            int_width_pseudo_MC_S.append(np.diff(int_pseudo_MC_S_ite_test).mean())\n",
    "            int_width_MC_S.append(np.diff(int_MC_S_ite_test).mean())\n",
    "            int_width_pseudo_MC_X.append(np.diff(int_pseudo_MC_X_ite_test).mean())\n",
    "            int_width_MC_X.append(np.diff(int_MC_X_ite_test).mean())\n",
    "            int_width_CT.append(np.diff(int_CT_ite_test).mean())\n",
    "            int_width_CM.append(np.diff(int_CM_ite_test).mean())\n",
    "            int_width_naive_ite.append(np.diff(int_naive_ite_test).mean())\n",
    "            int_width_exact_ite.append(np.diff(int_exact_ite_test).mean())\n",
    "            int_width_inexact_ite.append(np.diff(int_inexact_ite_test).mean())\n",
    "            int_width_y0_oracle.append(np.diff(int_y0_oracle).mean())\n",
    "            int_width_y1_oracle.append(np.diff(int_y1_oracle).mean())\n",
    "            int_width_ite_oracle.append(np.diff(int_ite_oracle).mean())\n",
    "            int_width_y_cond0.append(np.diff(int_y_cond0).mean())\n",
    "            int_width_y_cond1.append(np.diff(int_y_cond1).mean())\n",
    "\n",
    "            rmse_y0.append(np.sqrt(np.mean((y0_test - conformal_CT_learner.predict_y0(X_test, ps_test))**2)))\n",
    "            rmse_y1.append(np.sqrt(np.mean((y1_test - conformal_CT_learner.predict_y1(X_test, ps_test))**2)))\n",
    "            rmse_pseudo_MC_T_ite.append(np.sqrt(np.mean((ite_test - conformal_pseudo_MC_T_Learner.predict(X_test))**2)))\n",
    "            rmse_MC_T_ite.append(np.sqrt(np.mean((ite_test - conformal_MC_T_Learner.predict(X_test))**2)))\n",
    "            rmse_pseudo_MC_S_ite.append(np.sqrt(np.mean((ite_test - conformal_pseudo_MC_S_Learner.predict(X_test))**2)))\n",
    "            rmse_MC_S_ite.append(np.sqrt(np.mean((ite_test - conformal_MC_S_Learner.predict(X_test))**2)))\n",
    "            rmse_pseudo_MC_X_ite.append(np.sqrt(np.mean((ite_test - conformal_pseudo_MC_X_Learner.predict(X_test))**2)))\n",
    "            rmse_MC_X_ite.append(np.sqrt(np.mean((ite_test - conformal_MC_X_Learner.predict(X_test))**2)))\n",
    "            rmse_CT_ite.append(np.sqrt(np.mean((ite_test - conformal_CT_learner.predict(X_test, ps_test))**2)))\n",
    "            rmse_CM_ite.append(np.sqrt(np.mean((ite_test - conformal_Learner.predict(X_test))**2)))\n",
    "            rmse_naive_ite.append(np.sqrt(np.mean((ite_test - naive_WCP.predict(X_test))**2)))\n",
    "            rmse_exact_ite.append(np.sqrt(np.mean((ite_test - exact_wcp.predict(X_test))**2)))\n",
    "            rmse_inexact_ite.append(np.sqrt(np.mean((ite_test - inexact_wcp.predict(X_test))**2)))\n",
    "            rmse_y0_oracle.append(np.sqrt(np.mean((y0_test - conformal_y0.predict(X_test))**2)))\n",
    "            rmse_y1_oracle.append(np.sqrt(np.mean((y1_test - conformal_y1.predict(X_test))**2)))\n",
    "            rmse_ite_oracle.append(np.sqrt(np.mean((ite_test - conformal_ite.predict(X_test))**2)))\n",
    "            rmse_y_cond0.append(np.sqrt(np.mean((y_test[W_test == 0] - conformal_y_cond0.predict(X_test[W_test == 0]))**2)))\n",
    "            rmse_y_cond1.append(np.sqrt(np.mean((y_test[W_test == 1] - conformal_y_cond1.predict(X_test[W_test == 1]))**2)))\n",
    "        df_eval = pd.DataFrame({\n",
    "            \"coverage_y0\": coverage_y0,\n",
    "            \"coverage_y1\": coverage_y1,\n",
    "            \"coverage_pseudo_MC_T_ite\": coverage_pseudo_MC_T_ite,\n",
    "            \"coverage_MC_T_ite\": coverage_MC_T_ite,\n",
    "            \"coverage_pseudo_MC_S_ite\": coverage_pseudo_MC_S_ite,\n",
    "            \"coverage_MC_S_ite\": coverage_MC_S_ite,\n",
    "            \"coverage_pseudo_MC_X_ite\": coverage_pseudo_MC_X_ite,\n",
    "            \"coverage_MC_X_ite\": coverage_MC_X_ite,\n",
    "            \"coverage_CT_ite\": coverage_CT_ite,\n",
    "            \"coverage_CM_ite\": coverage_CM_ite,\n",
    "            \"coverage_naive_ite\": coverage_naive_ite,\n",
    "            \"coverage_exact_ite\": coverage_exact_ite,\n",
    "            \"coverage_inexact_ite\": coverage_inexact_ite,\n",
    "            \"coverage_y0_oracle\": coverage_y0_oracle,\n",
    "            \"coverage_y1_oracle\": coverage_y1_oracle,\n",
    "            \"coverage_ite_oracle\": coverage_ite_oracle,\n",
    "            \"coverage_y_cond0\": coverage_y_cond0,\n",
    "            \"coverage_y_cond1\": coverage_y_cond1,\n",
    "            \"int_width_y0\": int_width_y0,\n",
    "            \"int_width_y1\": int_width_y1,\n",
    "            \"int_width_pseudo_MC_T\": int_width_pseudo_MC_T,\n",
    "            \"int_width_MC_T\": int_width_MC_T,\n",
    "            \"int_width_pseudo_MC_S\": int_width_pseudo_MC_S,\n",
    "            \"int_width_MC_S\": int_width_MC_S,\n",
    "            \"int_width_pseudo_MC_X\": int_width_pseudo_MC_X,\n",
    "            \"int_width_MC_X\": int_width_MC_X,\n",
    "            \"int_width_CT\": int_width_CT,\n",
    "            \"int_width_CM\": int_width_CM,\n",
    "            \"int_width_naive_ite\": int_width_naive_ite,\n",
    "            \"int_width_exact_ite\": int_width_exact_ite,\n",
    "            \"int_width_inexact_ite\": int_width_inexact_ite,\n",
    "            \"int_width_y0_oracle\": int_width_y0_oracle,\n",
    "            \"int_width_y1_oracle\": int_width_y1_oracle,\n",
    "            \"int_width_ite_oracle\": int_width_ite_oracle,\n",
    "            \"int_width_y_cond0\": int_width_y_cond0,\n",
    "            \"int_width_y_cond1\": int_width_y_cond1,\n",
    "            \"rmse_y0\": rmse_y0,\n",
    "            \"rmse_y1\": rmse_y1,\n",
    "            \"rmse_pseudo_MC_T_ite\": rmse_pseudo_MC_T_ite,\n",
    "            \"rmse_MC_T_ite\": rmse_MC_T_ite,\n",
    "            \"rmse_pseudo_MC_S_ite\": rmse_pseudo_MC_S_ite,\n",
    "            \"rmse_MC_S_ite\": rmse_MC_S_ite,\n",
    "            \"rmse_pseudo_MC_X_ite\": rmse_pseudo_MC_X_ite,\n",
    "            \"rmse_MC_X_ite\": rmse_MC_X_ite,\n",
    "            \"rmse_CT_ite\": rmse_CT_ite,\n",
    "            \"rmse_CM_ite\": rmse_CM_ite,\n",
    "            \"rmse_naive_ite\": rmse_naive_ite,\n",
    "            \"rmse_exact_ite\": rmse_exact_ite,\n",
    "            \"rmse_inexact_ite\": rmse_inexact_ite,\n",
    "            \"rmse_y0_oracle\": rmse_y0_oracle,\n",
    "            \"rmse_y1_oracle\": rmse_y1_oracle,\n",
    "            \"rmse_ite_oracle\": rmse_ite_oracle,\n",
    "            \"rmse_y_cond0\": rmse_y_cond0,\n",
    "            \"rmse_y_cond1\": rmse_y_cond1,\n",
    "            \"alpha\": alphas\n",
    "        })\n",
    "        if max_min_y:\n",
    "            if heteroscedastic_epsilon:\n",
    "                df_eval.to_csv(f\"../../results/outputs/nie_wager/setup{setup_name}/eval/simulations_{setup_name}_{str(n)}_{learner_name}_{normalized_conformal_name}_max_min_y_heteroscedastic_eval.csv\", index=False)\n",
    "            else:\n",
    "                df_eval.to_csv(f\"../../results/outputs/nie_wager/setup{setup_name}/eval/simulations_{setup_name}_{str(n)}_{learner_name}_{normalized_conformal_name}_max_min_y_eval.csv\", index=False)\n",
    "        else:\n",
    "            if heteroscedastic_epsilon:\n",
    "                df_eval.to_csv(f\"../../results/outputs/nie_wager/setup{setup_name}/eval/simulations_{setup_name}_{str(n)}_{learner_name}_{normalized_conformal_name}_heteroscedastic_eval.csv\", index=False)\n",
    "            else:\n",
    "                df_eval.to_csv(f\"../../results/outputs/nie_wager/setup{setup_name}/eval/simulations_{setup_name}_{str(n)}_{learner_name}_{normalized_conformal_name}_eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Probability Calibrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7eb9a405abc4a259d0c594d85e84b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0baedcd5f4a4d9d9d4e1de0cf00254e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b180ed5419e4684a17a39fe52deb4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60baf7aa9b8473ea81f94574e094fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_save_data = True\n",
    "\n",
    "for i, setup in enumerate([simulate_nuisance_and_easy_treatment, simulate_randomized_trial, simulate_easy_propensity_difficult_baseline, simulate_unrelated_treatment_control]):\n",
    "    list_p_values_pseudo_MC_T = []\n",
    "    list_p_values_MC_T = []\n",
    "    list_p_values_pseudo_MC_S = []\n",
    "    list_p_values_MC_S = []\n",
    "    list_p_values_pseudo_MC_X = []\n",
    "    list_p_values_MC_X = []\n",
    "    list_p_values_CT = []\n",
    "    list_p_values_y0 = []\n",
    "    list_p_values_y1 = []\n",
    "    list_p_values_oracle = []\n",
    "\n",
    "    if i == 0:\n",
    "        setup_name = \"A\"\n",
    "    elif i == 1:\n",
    "        setup_name = \"B\"\n",
    "    elif i == 2:\n",
    "        setup_name = \"C\"\n",
    "    else:\n",
    "        setup_name = \"D\"\n",
    "    for n in tqdm(range(NSim)):\n",
    "        # Generate data\n",
    "        if get_save_data:\n",
    "            if heteroscedastic_epsilon:\n",
    "                path_train = f\"../../data/simulations/nie_wager/setup{setup_name}/simulations_{setup_name}_{n}_train_heteroscedastic.csv\"\n",
    "                path_test = f\"../../data/simulations/nie_wager/setup{setup_name}/simulations_{setup_name}_{n}_test_heteroscedastic.csv\"\n",
    "            else:\n",
    "                path_train = f\"../../data/simulations/nie_wager/setup{setup_name}/simulations_{setup_name}_{n}_train.csv\"\n",
    "                path_test = f\"../../data/simulations/nie_wager/setup{setup_name}/simulations_{setup_name}_{n}_test.csv\"\n",
    "            ds_train = pd.read_csv(path_train)\n",
    "            ds_test = pd.read_csv(path_test)\n",
    "            y_train = ds_train[\"y\"].values\n",
    "            y_test = ds_test[\"y\"].values\n",
    "            X_train = ds_train[[f\"X{i}\" for i in range(5)]].values\n",
    "            X_test = ds_test[[f\"X{i}\" for i in range(5)]].values\n",
    "            W_train = ds_train[\"W\"].values\n",
    "            W_test = ds_test[\"W\"].values\n",
    "            tau_train = ds_train[\"tau\"].values\n",
    "            tau_test = ds_test[\"tau\"].values\n",
    "            b_train = ds_train[\"b\"].values\n",
    "            b_test = ds_test[\"b\"].values\n",
    "            ps_train = ds_train[\"ps\"].values\n",
    "            ps_test = ds_test[\"ps\"].values\n",
    "            y0_train = ds_train[\"y0\"].values\n",
    "            y0_test = ds_test[\"y0\"].values\n",
    "            y1_train = ds_train[\"y1\"].values\n",
    "            y1_test = ds_test[\"y1\"].values\n",
    "            ite_train = ds_train[\"ite\"].values\n",
    "            ite_test = ds_test[\"ite\"].values\n",
    "        else:\n",
    "            y, X, treatment, tau, b, e, y0, y1 = setup(n=5000, c=0.0, heteroscedastic=heteroscedastic_epsilon)\n",
    "            ite = y1 - y0\n",
    "            ps = e\n",
    "            (y_train, y_test, X_train, X_test,\n",
    "            W_train, W_test,\n",
    "            tau_train, tau_test, b_train, b_test,\n",
    "            ps_train, ps_test, y0_train, y0_test,\n",
    "            y1_train, y1_test, ite_train, ite_test) = train_test_split(y, X, treatment, tau, b, ps, y0, y1, ite,\n",
    "                                                                        test_size=0.5)\n",
    "            df_X_train = pd.DataFrame(X_train, columns=[f\"X{i}\" for i in range(X_train.shape[1])])\n",
    "            df_X_test = pd.DataFrame(X_test, columns=[f\"X{i}\" for i in range(X_test.shape[1])])\n",
    "            ds_train = pd.concat((df_X_train, pd.DataFrame({\n",
    "                \"y\": y_train,\n",
    "                \"W\": W_train,\n",
    "                \"tau\": tau_train,\n",
    "                \"b\": b_train,\n",
    "                \"ps\": ps_train,\n",
    "                \"y0\": y0_train,\n",
    "                \"y1\": y1_train,\n",
    "                \"ite\": ite_train\n",
    "            })), axis=1)\n",
    "            ds_test = pd.concat((df_X_test, pd.DataFrame({\n",
    "                \"y\": y_test,\n",
    "                \"W\": W_test,\n",
    "                \"tau\": tau_test,\n",
    "                \"b\": b_test,\n",
    "                \"ps\": ps_test,\n",
    "                \"y0\": y0_test,\n",
    "                \"y1\": y1_test,\n",
    "                \"ite\": ite_test\n",
    "            })), axis=1)\n",
    "\n",
    "        # # Initialize the learner\n",
    "        conformal_pseudo_MC_T_Learner = CMC_T_Learner(\n",
    "            learner(),\n",
    "            learner(),\n",
    "            normalized_conformal=normalized_conformal,\n",
    "            pseudo_MC=True,\n",
    "            MC_samples=MC_samples,\n",
    "            max_min_y=max_min_y\n",
    "        )\n",
    "        conformal_pseudo_MC_T_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "        conformal_MC_T_Learner = CMC_T_Learner(\n",
    "            learner(),\n",
    "            learner(),\n",
    "            normalized_conformal=normalized_conformal,\n",
    "            pseudo_MC=False,\n",
    "            MC_samples=MC_samples,\n",
    "            max_min_y=max_min_y\n",
    "        )\n",
    "        conformal_MC_T_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "        # conformal_pseudo_MC_S_Learner = CMC_S_Learner(\n",
    "        #     learner(),\n",
    "        #     normalized_conformal=normalized_conformal,\n",
    "        #     pseudo_MC=True,\n",
    "        #     MC_samples=MC_samples,\n",
    "        #     max_min_y=max_min_y\n",
    "        # )\n",
    "        # with warnings.catch_warnings():\n",
    "        #     # Suppress warning that is thrown saying that calibration example is too small\n",
    "        #     # However, this is a bug in the crepes library in this case\n",
    "        #     conformal_pseudo_MC_S_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "        # conformal_MC_S_Learner = CMC_S_Learner(\n",
    "        #     learner(),\n",
    "        #     normalized_conformal=normalized_conformal,\n",
    "        #     pseudo_MC=False,\n",
    "        #     MC_samples=MC_samples,\n",
    "        #     max_min_y=max_min_y\n",
    "        # )\n",
    "\n",
    "        # with warnings.catch_warnings():\n",
    "        #     conformal_MC_S_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "\n",
    "        # conformal_pseudo_MC_X_Learner = CMC_X_Learner(\n",
    "        #     learner(),\n",
    "        #     learner(),\n",
    "        #     learner(),\n",
    "        #     normalized_conformal=normalized_conformal,\n",
    "        #     pseudo_MC=True,\n",
    "        #     MC_samples=MC_samples,\n",
    "        #     max_min_y=max_min_y\n",
    "        # )\n",
    "        # # Fit the learner\n",
    "        # with warnings.catch_warnings():\n",
    "        #     warnings.simplefilter(\"ignore\")\n",
    "        #     conformal_pseudo_MC_X_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "        # conformal_MC_X_Learner = CMC_X_Learner(\n",
    "        #     learner(),\n",
    "        #     learner(),\n",
    "        #     learner(),\n",
    "        #     normalized_conformal=normalized_conformal,\n",
    "        #     pseudo_MC=False,\n",
    "        #     MC_samples=MC_samples,\n",
    "        #     max_min_y=max_min_y\n",
    "        # )\n",
    "\n",
    "        # # Fit the learner\n",
    "        # with warnings.catch_warnings():\n",
    "        #     warnings.simplefilter(\"ignore\")\n",
    "        #     conformal_MC_X_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "        conformal_CT_learner = CCT_Learner(learner(), learner(), normalized_conformal=normalized_conformal)\n",
    "        conformal_CT_learner.fit(X_train, y_train, W_train, p=ps_train)\n",
    "        (X_train_nuisance, X_train_cal,\n",
    "            y_train_nuisance, y_train_cal,\n",
    "            y0_train_nuisance, y0_train_cal,\n",
    "            y1_train_nuisance, y1_train_cal,\n",
    "            W_train_nuisance, W_train_cal,\n",
    "            ite_train_nuisance, ite_train_cal) = train_test_split(\n",
    "                X_train, y_train, y0_train, y1_train, W_train, ite_train, test_size=0.5, random_state=n\n",
    "        )\n",
    "        conformal_ite_oracle = WrapRegressor(learner())\n",
    "        conformal_ite_oracle.fit(X_train_nuisance, ite_train_nuisance)\n",
    "        conformal_ite_oracle.calibrate(X_train_cal, ite_train_cal, cps=True)\n",
    "        # p-values\n",
    "        list_p_values_pseudo_MC_T.append(conformal_pseudo_MC_T_Learner.predict_p_value(X_test, ite_test))\n",
    "        list_p_values_MC_T.append(conformal_MC_T_Learner.predict_p_value(X_test, ite_test))\n",
    "        # list_p_values_pseudo_MC_S.append(conformal_pseudo_MC_S_Learner.predict_p_value(X_test, ite_test))\n",
    "        # list_p_values_MC_S.append(conformal_MC_S_Learner.predict_p_value(X_test, ite_test))\n",
    "        # list_p_values_pseudo_MC_X.append(conformal_pseudo_MC_X_Learner.predict_p_value(X_test, ite_test))\n",
    "        # list_p_values_MC_X.append(conformal_MC_X_Learner.predict_p_value(X_test, ite_test))\n",
    "        list_p_values_CT.append(conformal_CT_learner.predict_p_value(X_test, ite_test, p=ps_test))\n",
    "        list_p_values_y0.append(conformal_CT_learner.predict_p_value_y0(X_test, y0_test, p=ps_test))\n",
    "        list_p_values_y1.append(conformal_CT_learner.predict_p_value_y1(X_test, y1_test, p=ps_test))\n",
    "        list_p_values_oracle.append(conformal_ite_oracle.predict_cps(X_test, y=ite_test))\n",
    "\n",
    "    dict_p_values = {\n",
    "            \"pseudo_MC_T\": np.concatenate(list_p_values_pseudo_MC_T),\n",
    "            \"MC_T\": np.concatenate(list_p_values_MC_T),\n",
    "            # \"pseudo_MC_S\": np.concatenate(list_p_values_pseudo_MC_S),\n",
    "            # \"MC_S\": np.concatenate(list_p_values_MC_S),\n",
    "            # \"pseudo_MC_X\": np.concatenate(list_p_values_pseudo_MC_X),\n",
    "            # \"MC_X\": np.concatenate(list_p_values_MC_X),\n",
    "            \"CT\": np.concatenate(list_p_values_CT),\n",
    "            \"y0\": np.concatenate(list_p_values_y0),\n",
    "            \"y1\": np.concatenate(list_p_values_y1),\n",
    "            \"oracle\": np.concatenate(list_p_values_oracle),\n",
    "    }\n",
    "    df_p_values = pd.DataFrame(dict_p_values)\n",
    "    if max_min_y:\n",
    "        if heteroscedastic_epsilon:\n",
    "            df_p_values.to_csv(f\"../../results/outputs/nie_wager/setup{setup_name}/p_values/simulations_{setup_name}_{learner_name}_{normalized_conformal_name}_max_min_y_heteroscedastic_p_values.csv\", index=False)\n",
    "        else:\n",
    "            df_p_values.to_csv(f\"../../results/outputs/nie_wager/setup{setup_name}/p_values/simulations_{setup_name}_{learner_name}_{normalized_conformal_name}_max_min_y_p_values.csv\", index=False)\n",
    "    else:\n",
    "        if heteroscedastic_epsilon:\n",
    "            df_p_values.to_csv(f\"../../results/outputs/nie_wager/setup{setup_name}/p_values/simulations_{setup_name}_{learner_name}_{normalized_conformal_name}_heteroscedastic_p_values.csv\", index=False)\n",
    "        else:\n",
    "            df_p_values.to_csv(f\"../../results/outputs/nie_wager/setup{setup_name}/p_values/simulations_{setup_name}_{learner_name}_{normalized_conformal_name}_p_values.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bbb5c5d0124f8784405e0920db7926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5a82060d9d42d98788b3393dfad60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05046667614b420284be01bd69805217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965a0bd7544f415e8b807217be328770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_save_data = True\n",
    "\n",
    "for i, setup in enumerate([simulate_nuisance_and_easy_treatment, simulate_randomized_trial, simulate_easy_propensity_difficult_baseline, simulate_unrelated_treatment_control]):\n",
    "    list_p_values_pseudo_MC_T = []\n",
    "    list_p_values_MC_T = []\n",
    "    list_p_values_pseudo_MC_S = []\n",
    "    list_p_values_MC_S = []\n",
    "    list_p_values_pseudo_MC_X = []\n",
    "    list_p_values_MC_X = []\n",
    "    list_p_values_CT = []\n",
    "    list_p_values_y0 = []\n",
    "    list_p_values_y1 = []\n",
    "    list_p_values_oracle = []\n",
    "\n",
    "    if i == 0:\n",
    "        setup_name = \"A\"\n",
    "    elif i == 1:\n",
    "        setup_name = \"B\"\n",
    "    elif i == 2:\n",
    "        setup_name = \"C\"\n",
    "    else:\n",
    "        setup_name = \"D\"\n",
    "    for n in tqdm(range(NSim)):\n",
    "        # Generate data\n",
    "        if get_save_data:\n",
    "            if heteroscedastic_epsilon:\n",
    "                path_train = f\"../../data/simulations/nie_wager/setup{setup_name}/simulations_{setup_name}_{n}_train_heteroscedastic.csv\"\n",
    "                path_test = f\"../../data/simulations/nie_wager/setup{setup_name}/simulations_{setup_name}_{n}_test_heteroscedastic.csv\"\n",
    "            else:\n",
    "                path_train = f\"../../data/simulations/nie_wager/setup{setup_name}/simulations_{setup_name}_{n}_train.csv\"\n",
    "                path_test = f\"../../data/simulations/nie_wager/setup{setup_name}/simulations_{setup_name}_{n}_test.csv\"\n",
    "            ds_train = pd.read_csv(path_train)\n",
    "            ds_test = pd.read_csv(path_test)\n",
    "            y_train = ds_train[\"y\"].values\n",
    "            y_test = ds_test[\"y\"].values\n",
    "            X_train = ds_train[[f\"X{i}\" for i in range(5)]].values\n",
    "            X_test = ds_test[[f\"X{i}\" for i in range(5)]].values\n",
    "            W_train = ds_train[\"W\"].values\n",
    "            W_test = ds_test[\"W\"].values\n",
    "            tau_train = ds_train[\"tau\"].values\n",
    "            tau_test = ds_test[\"tau\"].values\n",
    "            b_train = ds_train[\"b\"].values\n",
    "            b_test = ds_test[\"b\"].values\n",
    "            ps_train = ds_train[\"ps\"].values\n",
    "            ps_test = ds_test[\"ps\"].values\n",
    "            y0_train = ds_train[\"y0\"].values\n",
    "            y0_test = ds_test[\"y0\"].values\n",
    "            y1_train = ds_train[\"y1\"].values\n",
    "            y1_test = ds_test[\"y1\"].values\n",
    "            ite_train = ds_train[\"ite\"].values\n",
    "            ite_test = ds_test[\"ite\"].values\n",
    "        else:\n",
    "            y, X, treatment, tau, b, e, y0, y1 = setup(n=5000, c=0.0, heteroscedastic=heteroscedastic_epsilon)\n",
    "            ite = y1 - y0\n",
    "            ps = e\n",
    "            (y_train, y_test, X_train, X_test,\n",
    "            W_train, W_test,\n",
    "            tau_train, tau_test, b_train, b_test,\n",
    "            ps_train, ps_test, y0_train, y0_test,\n",
    "            y1_train, y1_test, ite_train, ite_test) = train_test_split(y, X, treatment, tau, b, ps, y0, y1, ite,\n",
    "                                                                        test_size=0.5)\n",
    "            df_X_train = pd.DataFrame(X_train, columns=[f\"X{i}\" for i in range(X_train.shape[1])])\n",
    "            df_X_test = pd.DataFrame(X_test, columns=[f\"X{i}\" for i in range(X_test.shape[1])])\n",
    "            ds_train = pd.concat((df_X_train, pd.DataFrame({\n",
    "                \"y\": y_train,\n",
    "                \"W\": W_train,\n",
    "                \"tau\": tau_train,\n",
    "                \"b\": b_train,\n",
    "                \"ps\": ps_train,\n",
    "                \"y0\": y0_train,\n",
    "                \"y1\": y1_train,\n",
    "                \"ite\": ite_train\n",
    "            })), axis=1)\n",
    "            ds_test = pd.concat((df_X_test, pd.DataFrame({\n",
    "                \"y\": y_test,\n",
    "                \"W\": W_test,\n",
    "                \"tau\": tau_test,\n",
    "                \"b\": b_test,\n",
    "                \"ps\": ps_test,\n",
    "                \"y0\": y0_test,\n",
    "                \"y1\": y1_test,\n",
    "                \"ite\": ite_test\n",
    "            })), axis=1)\n",
    "\n",
    "        # # Initialize the learner\n",
    "        conformal_pseudo_MC_T_Learner = CMC_T_Learner(\n",
    "            learner(),\n",
    "            learner(),\n",
    "            normalized_conformal=normalized_conformal,\n",
    "            pseudo_MC=True,\n",
    "            MC_samples=MC_samples,\n",
    "            max_min_y=max_min_y\n",
    "        )\n",
    "        conformal_pseudo_MC_T_Learner.fit(X_train, y_train, W_train)\n",
    "\n",
    "        conformal_MC_T_Learner = CMC_T_Learner(\n",
    "            learner(),\n",
    "            learner(),\n",
    "            normalized_conformal=normalized_conformal,\n",
    "            pseudo_MC=False,\n",
    "            MC_samples=MC_samples,\n",
    "            max_min_y=max_min_y\n",
    "        )\n",
    "        conformal_MC_T_Learner.fit(X_train, y_train, W_train)\n",
    "\n",
    "        # conformal_pseudo_MC_S_Learner = CMC_S_Learner(\n",
    "        #     learner(),\n",
    "        #     normalized_conformal=normalized_conformal,\n",
    "        #     pseudo_MC=True,\n",
    "        #     MC_samples=MC_samples,\n",
    "        #     max_min_y=max_min_y\n",
    "        # )\n",
    "        # with warnings.catch_warnings():\n",
    "        #     # Suppress warning that is thrown saying that calibration example is too small\n",
    "        #     # However, this is a bug in the crepes library in this case\n",
    "        #     conformal_pseudo_MC_S_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "        # conformal_MC_S_Learner = CMC_S_Learner(\n",
    "        #     learner(),\n",
    "        #     normalized_conformal=normalized_conformal,\n",
    "        #     pseudo_MC=False,\n",
    "        #     MC_samples=MC_samples,\n",
    "        #     max_min_y=max_min_y\n",
    "        # )\n",
    "\n",
    "        # with warnings.catch_warnings():\n",
    "        #     conformal_MC_S_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "\n",
    "        # conformal_pseudo_MC_X_Learner = CMC_X_Learner(\n",
    "        #     learner(),\n",
    "        #     learner(),\n",
    "        #     learner(),\n",
    "        #     normalized_conformal=normalized_conformal,\n",
    "        #     pseudo_MC=True,\n",
    "        #     MC_samples=MC_samples,\n",
    "        #     max_min_y=max_min_y\n",
    "        # )\n",
    "        # # Fit the learner\n",
    "        # with warnings.catch_warnings():\n",
    "        #     warnings.simplefilter(\"ignore\")\n",
    "        #     conformal_pseudo_MC_X_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "        # conformal_MC_X_Learner = CMC_X_Learner(\n",
    "        #     learner(),\n",
    "        #     learner(),\n",
    "        #     learner(),\n",
    "        #     normalized_conformal=normalized_conformal,\n",
    "        #     pseudo_MC=False,\n",
    "        #     MC_samples=MC_samples,\n",
    "        #     max_min_y=max_min_y\n",
    "        # )\n",
    "\n",
    "        # # Fit the learner\n",
    "        # with warnings.catch_warnings():\n",
    "        #     warnings.simplefilter(\"ignore\")\n",
    "        #     conformal_MC_X_Learner.fit(X_train, y_train, W_train, ps_train)\n",
    "\n",
    "        conformal_CT_learner = CCT_Learner(learner(), learner(), normalized_conformal=normalized_conformal)\n",
    "        conformal_CT_learner.fit(X_train, y_train, W_train)\n",
    "        (X_train_nuisance, X_train_cal,\n",
    "            y_train_nuisance, y_train_cal,\n",
    "            y0_train_nuisance, y0_train_cal,\n",
    "            y1_train_nuisance, y1_train_cal,\n",
    "            W_train_nuisance, W_train_cal,\n",
    "            ite_train_nuisance, ite_train_cal) = train_test_split(\n",
    "                X_train, y_train, y0_train, y1_train, W_train, ite_train, test_size=0.5, random_state=n\n",
    "        )\n",
    "        conformal_ite_oracle = WrapRegressor(learner())\n",
    "        conformal_ite_oracle.fit(X_train_nuisance, ite_train_nuisance)\n",
    "        conformal_ite_oracle.calibrate(X_train_cal, ite_train_cal, cps=True)\n",
    "        # p-values\n",
    "        list_p_values_pseudo_MC_T.append(conformal_pseudo_MC_T_Learner.predict_p_value(X_test, ite_test))\n",
    "        list_p_values_MC_T.append(conformal_MC_T_Learner.predict_p_value(X_test, ite_test))\n",
    "        # list_p_values_pseudo_MC_S.append(conformal_pseudo_MC_S_Learner.predict_p_value(X_test, ite_test))\n",
    "        # list_p_values_MC_S.append(conformal_MC_S_Learner.predict_p_value(X_test, ite_test))\n",
    "        # list_p_values_pseudo_MC_X.append(conformal_pseudo_MC_X_Learner.predict_p_value(X_test, ite_test))\n",
    "        # list_p_values_MC_X.append(conformal_MC_X_Learner.predict_p_value(X_test, ite_test))\n",
    "        list_p_values_CT.append(conformal_CT_learner.predict_p_value(X_test, ite_test))\n",
    "        list_p_values_y0.append(conformal_CT_learner.predict_p_value_y0(X_test, y0_test))\n",
    "        list_p_values_y1.append(conformal_CT_learner.predict_p_value_y1(X_test, y1_test))\n",
    "        list_p_values_oracle.append(conformal_ite_oracle.predict_cps(X_test, y=ite_test))\n",
    "\n",
    "    dict_p_values = {\n",
    "            \"pseudo_MC_T\": np.concatenate(list_p_values_pseudo_MC_T),\n",
    "            \"MC_T\": np.concatenate(list_p_values_MC_T),\n",
    "            # \"pseudo_MC_S\": np.concatenate(list_p_values_pseudo_MC_S),\n",
    "            # \"MC_S\": np.concatenate(list_p_values_MC_S),\n",
    "            # \"pseudo_MC_X\": np.concatenate(list_p_values_pseudo_MC_X),\n",
    "            # \"MC_X\": np.concatenate(list_p_values_MC_X),\n",
    "            \"CT\": np.concatenate(list_p_values_CT),\n",
    "            \"y0\": np.concatenate(list_p_values_y0),\n",
    "            \"y1\": np.concatenate(list_p_values_y1),\n",
    "            \"oracle\": np.concatenate(list_p_values_oracle),\"\n",
    "    }\n",
    "    df_p_values = pd.DataFrame(dict_p_values)\n",
    "    if max_min_y:\n",
    "        if heteroscedastic_epsilon:\n",
    "            df_p_values.to_csv(f\"../../results/outputs/nie_wager/setup{setup_name}/p_values/simulations_{setup_name}_{learner_name}_{normalized_conformal_name}_max_min_y_heteroscedastic_unweighted_p_values.csv\", index=False)\n",
    "        else:\n",
    "            df_p_values.to_csv(f\"../../results/outputs/nie_wager/setup{setup_name}/p_values/simulations_{setup_name}_{learner_name}_{normalized_conformal_name}_max_min_y_unweighted_p_values.csv\", index=False)\n",
    "    else:\n",
    "        if heteroscedastic_epsilon:\n",
    "            df_p_values.to_csv(f\"../../results/outputs/nie_wager/setup{setup_name}/p_values/simulations_{setup_name}_{learner_name}_{normalized_conformal_name}_heteroscedastic_unweighted_p_values.csv\", index=False)\n",
    "        else:\n",
    "            df_p_values.to_csv(f\"../../results/outputs/nie_wager/setup{setup_name}/p_values/simulations_{setup_name}_{learner_name}_{normalized_conformal_name}_unweighted_p_values.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
